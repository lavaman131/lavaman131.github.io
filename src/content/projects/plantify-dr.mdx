---
title: "Plant Disease Detection App"
cover: "../../assets/images/projects/plantify-dr/thumbnail.png"
githubUrl: "https://github.com/lavaman131/PlantifyDr"
---

import { Image } from "astro:assets";

import Resources from "../../assets/images/projects/plantify-dr/report/Resources.png";
import Flowchart from "../../assets/images/projects/plantify-dr/report/Flowchart.jpg";
import ResNet50 from "../../assets/images/projects/plantify-dr/report/ResNet50.png";
import SkipConnection from "../../assets/images/projects/plantify-dr/report/SkipConnection.png";
import CosineAnnealing from "../../assets/images/projects/plantify-dr/report/CosineAnnealing.png";
import TomatoTable from "../../assets/images/projects/plantify-dr/report/Tomato_Table.png";
import TomatoGraph from "../../assets/images/projects/plantify-dr/report/Tomato_Graph.png";
import TomatoConfusionMatrix from "../../assets/images/projects/plantify-dr/report/Tomato_Confusion_Matrix.png";
import TomatoResults from "../../assets/images/projects/plantify-dr/report/Tomato_Results.png";

## Video Explanation & Demo

<iframe 
  width="750" 
  height="422"
  src="https://www.youtube.com/embed/uRbDXtMIHRk" 
  title="PlantifyDr Demo"
  frameborder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
  allowfullscreen
/>

## Built With

- [fastai](https://docs.fast.ai/) - A deep learning library written in Python based off of PyTorch
- [Flask](https://flask.palletsprojects.com/en/1.1.x/) - Used as web framework for deployment
- [Docker Compose](https://docs.docker.com/compose/) - Used to run application
- [WSGI](https://wsgi.readthedocs.io/en/latest/what.html) - Web Server Gateway Interface to communicate with web application
- [AWS](https://aws.amazon.com/) - For hosting ML models
- [Swift](https://developer.apple.com/swift/) - For creating iOS app
- [Postman](https://www.postman.com/) - For testing API

<Image src={Resources} alt="Resources" />



## Project Plan

<Image src={Flowchart} alt="Flowchart" />

## Model architecture

- The power of convolutional neural networks (CNNs), specifically, `ResNet-50` allows computer to detect patterns in the pixels of images that humans cannot see.
- As opposed to other ResNet variants, ResNet-50 provides compromise of additional model layers (50) while keeping model storage relatively low (~100mb).

  <Image src={ResNet50} alt="ResNet50" />

- Finally, skip connections helps mitigate vanishing gradient and model performance will perform at least as good as previous layer.

  <Image src={SkipConnection} alt="SkipConnection" />

## Deep Learning techniques used

1. **Model training** with `Learning rate (LR) scheduler` using `cosine annealing` as opposed to more traditional LR scheduling from `lr_max/div`Â toÂ `lr_max` where `div` is a number (100000.0 in my case & default for fastai library) for optimal learning rate for better training results

2. **Fine tuning model** withÂ `freeze`Â forÂ `freeze_epochs` (transfer learning)Â then withÂ `unfreeze`Â fromÂ epochsÂ using `discriminative LR` (lower LR for earlier layers and greater LR for later layers)

<Image src={CosineAnnealing} alt="CosineAnnealing" />

## Results

My final models each achieved a validation `accuracy of >= 99.2%`.

#### Here are my results for tomatos:

<Image src={TomatoTable} alt="TomatoTable" />
<Image src={TomatoGraph} alt="TomatoGraph" />
<Image src={TomatoConfusionMatrix} alt="TomatoConfusionMatrix" />
<Image src={TomatoResults} alt="TomatoResults" />

#### Statistical Analysis:

- The `Matthews correlation coefficient (MCC)` is in essence a correlation coefficient value between -1 and +1 commonly used in machine learning that considers class imbalances. A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction. It takes into consideration true and false positives and negatives. My model achieved a `MCC of 0.991`.
- The `F1 score` can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. This is also helpful in considering class imbalances. My model achieved an `F1 score of 0.992`.
- As shown in the train loss and valid loss columns and the Epochs vs Training and Validation graph my model has a `good fit` after `12 epochs` of training
  - A `good fit` is identified by a training and validation loss that decreases to a point of stability with a minimal gap between the two final loss values.
- Therefore, based on the previous statistics it can be inferred that the `validation accuracy` from my results is reliable to diagnose and treat plant diseases.

## Experiment for yourself:

In your terminal run:

```bash
pip install -r requirements.txt
```

Get the data from:
https://www.kaggle.com/lavaman151/plantifydr-dataset 

## Points of Improvement:

- In the future, I would like to add more plant types and diseases to my dataset.
- Additionally, I want to add more features like plant nutritional deficiency recognition which can help provide insight into pesticide free and biological treatment of plants.
- Something else I might have done differently was build my app in React Native or Flutter as it would have allowed me to bundle my iOS and Android app together which would be easier to do as the only developer.
- Finally, I would like to implement and experiment with more state-of-the art models including XResNet and its variants for transfer learning on different datasets.

## Final Words

I hope my experiences building this app can shed some light into someone who is looking to get started on a similar ML project. This project was my first experience with deep learning and sparked my passion for computer vision. I loved every bit of the four months I spent on this project.

## Get my app

My app was available previously on the App Store and Google Play Store, however, it is no longer available since I wasn't able to afford to renew my subscription and the cost of maintaining the services for the app was too high at the time.

## ðŸ‘¥ Collaborators

* None

