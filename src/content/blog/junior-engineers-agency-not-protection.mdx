---
title: "Junior Engineers Don't Need Protection from AI. They Need Agency."
date: "2026-02-24"
authors: "Alex Lavaee, Norin Lavaee"
description: "The discourse assumes juniors need protection from AI tools. They don't. They need trust, a disciplined workflow, and room to build capability on their own terms."
cover: "../../assets/images/blog/junior-engineers-agency-not-protection/cover.png"
---

import BlogCTA from "../../components/blog/BlogCTA.astro";

The discourse around junior engineers and AI has it backwards.

The prevailing assumption is that juniors need guardrails ‚Äî that without careful supervision, they'll become dependent on AI tools, skip the fundamentals, and produce fragile code they don't understand. Organizations debate how to "protect" early-career engineers from over-reliance on copilots and code generators.

I'm a junior engineer. I'm not writing this from the outside looking in. I'm writing it from inside the shift. And I can tell you: the instinct to protect is the wrong instinct.

What builds capability isn't insulation from the technology. It's agency.

## The Protectionist Fallacy

The argument goes like this: juniors lack the experience to evaluate AI output. They'll accept bad suggestions blindly. They'll skip learning data structures, systems design, and debugging. They'll become "AI-dependent" engineers who freeze the moment their copilot goes down.

This framing has two problems.

First, it assumes the only way to learn fundamentals is the traditional way ‚Äî years of writing everything by hand before being trusted with more powerful tools. Second, it treats juniors as fragile rather than adaptable.

Neither holds up.

My organization gave me room to experiment with AI tools and build AI-powered systems as core work ‚Äî not a side project. I was trusted to research approaches, propose solutions, collaborate openly with senior engineers, and ship production systems. That trust is what built capability. Not the absence of tools.

The engineers who grow fastest aren't the ones shielded from complexity. They're the ones given real problems and the autonomy to solve them ‚Äî with whatever tools are available. AI agents are just the latest and most powerful tool in that category.

## Research Is Where Juniors Actually Learn

For juniors adopting AI coding agents, the workflow I recommend has four phases: **Research. Plan. Implement. Verify.**

Research is the most important phase, and most people skip it entirely.

Use AI to explore the codebase. Surface existing patterns. Understand architectural decisions and _why_ they were made. Propose multiple solutions with explicit tradeoffs. This is where you learn architecture and design ‚Äî not by having someone hand you a diagram, but by investigating the system yourself and presenting options to your team.

This maps directly to a concept called **context engineering** ‚Äî the idea that the quality of an AI agent's output depends entirely on the quality of context you provide it. The [Advanced Context Engineering for Coding Agents (ACE-FCA)](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md) framework formalizes this into a discipline. Its core insight is deceptively simple: without changing the model itself, the contents of your context window are the _only_ lever you have to affect the quality of the output.

For juniors, this matters more than it does for seniors. Seniors have years of pattern recognition that compensate for imprecise context. Juniors don't have that yet. But the research phase _is_ how you build that pattern recognition ‚Äî faster than traditional osmosis ever could. Every time you investigate a codebase, map its dependencies, and surface its conventions before writing a single line of code, you're doing the architectural learning that used to take years of passive exposure.

Don't skip this phase. It's the most valuable time you'll spend.

## Plans Are Where Senior Engineers Add the Most Value

Write up your approach. Describe what you're going to change, why, and what tradeoffs you're accepting. Then get it reviewed.

This is where senior engineers add the most value ‚Äî shaping your judgment, not writing your code. Every "have you considered X?" teaches you to see around corners. You absorb the design sensibilities of your reviewers. Over time, you start anticipating what good looks like _before_ the review happens. That's how taste develops.

The ACE-FCA framework makes the same point from a systems perspective: planning errors compound exponentially. One flawed research document can generate thousands of lines of problematic code. One flawed plan can too. Human review should focus on research and planning artifacts ‚Äî not individual lines of generated code. The highest-leverage place for a senior engineer to intervene is at the plan, not at the pull request.

For juniors, this reframes the senior-junior relationship entirely. You're not waiting for seniors to write code and explain it to you. You're proposing plans and getting your _thinking_ reviewed. That's a fundamentally different learning loop ‚Äî and a faster one. You're building the muscle of architectural reasoning, not just the muscle of syntax.

## Then Let AI Implement ‚Äî but Don't Outsource the Thinking

You already did the hard work. The research surfaced the patterns. The plan was reviewed and refined. Now the code is the output, not the insight.

This is where AI coding agents genuinely shine. Once the context is right and the plan is precise, implementation becomes the most mechanical phase. Let the agent handle it.

But don't outsource the critical thinking.

Push back on the model. Question its choices. Read the generated code line by line. The instant gratification of watching code appear is real ‚Äî and like any instant gratification, it doesn't serve you long-term. Stay in the research and planning phases long enough to actually learn. That's where the compounding happens.

And you still need to learn to code manually. Today, models get stuck. They produce code you need to adjust, debug, or rewrite entirely. You need to be able to take over when the agent can't get there. That skill isn't optional yet ‚Äî and building it makes you a better operator of the tools anyway. When you understand what the agent is doing at the implementation level, you catch the subtle bugs that automated verification misses.

<BlogCTA />

## A Blank Slate Is an Advantage

Here's what most people miss: juniors are _uniquely positioned_ for this shift.

No legacy assumptions about what the software development lifecycle should look like. No muscle memory for workflows that are being automated. No emotional attachment to pull request rituals refined over a decade, or code review habits built for a world where humans wrote every line.

A blank slate isn't a weakness. It's a competitive advantage.

Seniors have to _unlearn_ before they can adapt. Juniors don't carry that weight. Juniors who adopt disciplined workflows from day one ‚Äî research, plan, implement, verify ‚Äî will develop an intuition for how models reason and where they fall short. That intuition is what separates someone who _uses_ AI from someone who _builds_ with it.

Understanding how these models work at a fundamental level ‚Äî their reasoning patterns, their failure modes, how to steer them effectively ‚Äî is the meta-skill of the next decade. Juniors who go deep here won't just keep up with the shift. They'll shape it.

## The Gap Closes With Reps

If research and planning take you longer than the senior next to you ‚Äî that's expected. They have years of pattern recognition you haven't built yet. The delta closes with reps.

Two things that accelerate the curve:

**Contribute to open source.** Study how large projects handle scale ‚Äî test infrastructure, modular architecture, CI/CD patterns. These patterns become your vocabulary when you're directing agents. When you can articulate "this should follow the repository pattern used in the data layer" instead of "write me a database function," you get dramatically better output from every tool in your stack.

**Study context engineering as a discipline.** The [ACE-FCA framework](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md) is a strong starting point. It covers how to structure research phases, how to manage agent context windows for maximum signal, and how to review AI-generated plans at the right level of abstraction. Every cycle through research-plan-implement builds your intuition for how models reason and where they fall short. That's transferable knowledge that compounds across every tool you'll use for the rest of your career.

---

## Give Juniors Agency

The junior engineers who get deep with these tools ‚Äî not just with agents, but with the fundamental models underneath them ‚Äî will be the ones who enable the next generation of developers.

Not because they were protected from the technology. Because they were trusted to use it.

Give juniors agency. They'll surprise you.

---

## Resources for Junior Engineers

If you're a junior engineer looking to develop a disciplined workflow with AI coding agents, these resources are worth your time:

- **[Advanced Context Engineering for Coding Agents (ACE-FCA)](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md)** ‚Äî A comprehensive framework for structuring research, planning, and implementation phases when working with AI coding agents. Covers context window management, the hierarchy of context problems (incorrect > missing > noisy), and how to review AI-generated work at the right level of abstraction. If you read one resource on this list, make it this one.

Check out the posts, writings, and videos from these people ‚Äî they're consistently putting out some of the best thinking on AI-assisted engineering:

- **Dex Horthy** ‚Äî [ùïè](https://x.com/dexhorthy) ¬∑ Creator of [12-Factor Agents](https://github.com/humanlayer/12-factor-agents) and the term "context engineering." His talks and writing on agent workflows are essential.

- **Geoff Huntley** ‚Äî [ùïè](https://x.com/GeoffreyHuntley) ¬∑ [Blog](https://ghuntley.com/) ¬∑ Invented the Ralph Wiggum technique, writes extensively on backpressure, context engineering, and autonomous agent loops. Runs workshops on building coding agents from scratch.

- **Simon Willison** ‚Äî [ùïè](https://x.com/simonw) ¬∑ [Blog](https://simonwillison.net/) ¬∑ One of the most prolific and rigorous writers on LLMs, prompt engineering, and AI tooling. His blog is a living reference for understanding how these models actually work in practice.

- **Paolo Perrone** ‚Äî [LinkedIn](https://www.linkedin.com/in/paoloperrone/) ¬∑ Creates content for [AlphaSignal](https://alphasignal.ai/), one of the best AI newsletters for staying current on research and tooling developments.

- **Boris Cherny** ‚Äî [ùïè](https://x.com/bcherny) ¬∑ Creator of Claude Code. His interviews and threads on AI-first workflows, parallel agent sessions, and the shift from "software engineer" to "builder" are worth studying closely.

Finally ‚Äî and this isn't a link, it's a practice: **try the top coding agents yourself and notice the differences.** Use [Claude Code](https://docs.anthropic.com/en/docs/claude-code), [Cursor](https://www.cursor.com/), [Windsurf](https://windsurf.com/), [Codex](https://openai.com/codex/), [Amp](https://ampcode.com/), [GitHub Copilot CLI](https://github.com/features/copilot/cli), [Opencode](https://opencode.ai/), and others side by side on real tasks. Pay attention to how the underlying models reason differently, where the scaffolding helps and where it gets in the way, and what each tool does well or poorly. This builds the most important muscle: intuition for what's coming next. You'll start to see the gaps before they're filled, and you'll be prepared when they are.


